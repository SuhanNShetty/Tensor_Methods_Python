{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Suhan Shetty (suhan.n.shetty@gmail.com | suhan.shetty@idiap.ch)\n",
    "\n",
    "This notebook implements multilinear PCA based regression for tensor time series modeling\n",
    "\n",
    "References:\n",
    "\n",
    " - Dynamic tensor time series modeling and analysis, https://ieeexplore.ieee.org/abstract/document/7798500\n",
    "\n",
    " - MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    " https://www.jstor.org/stable/43826417\n",
    " \n",
    " - Multilinear Dynamical Systems for Tensor Time Series: https://people.eecs.berkeley.edu/~russell/papers/nips13-tensor.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "from tensorly.base import unfold\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import pinv\n",
    "from tensorly.tenalg import kronecker as kron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 # dimension of each output tensor Yi's\n",
    "T = 10 # length of time series\n",
    "shape_Yi = [20,25,4]\n",
    "I = [T,*shape_Yi]\n",
    "\n",
    "# Generate data Y from some low-rank structure \n",
    "J0 = [8,5,3] # ranks of the factor matrices\n",
    "U0 = [np.random.rand(I[n+1],J0[n]) for n in range(N)] #Factors\n",
    "X0 = np.random.rand(T,*J0) # Core array\n",
    "\n",
    "Y = multi_mode_dot(X0,U0, modes=[n+1 for n in range(N)]) #Output tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean = np.average(Y,axis=0)\n",
    "Yn = Y - Y_mean # mean zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpca(Y,J,tol=1e-2):\n",
    "    '''\n",
    "    Y: an N-dimensional Tensor\n",
    "    J: Desired ranks of the tucker factors (increase J for better approximation)\n",
    "    tol: tolerance for convergence of mpca iterations\n",
    "    '''\n",
    "    Yn = Y-np.average(Y,axis=0)\n",
    "    # Initialization\n",
    "    U = [None]*(len(Yn.shape)-1)\n",
    "    for n in range(N): # across all modes\n",
    "        mode_n_sum = 0\n",
    "        for t in range(T):\n",
    "            unfold_along_n = unfold(Yn[t],mode=n)\n",
    "            mode_n_sum += unfold_along_n@unfold_along_n.T\n",
    "        U[n] = eigsh(mode_n_sum,k=J[n])[1] # faster way to compute eigen vectors (for symmetric matrices)\n",
    "        # Note: The most significant eigen vectors are arranged in the last columns of U\n",
    "    \n",
    "    # Local optimization\n",
    "    X = multi_mode_dot(Yn,U,modes=[1+i for i in range(N)], transpose=True)\n",
    "    Yn_apprx0 = multi_mode_dot(X,U,modes=[1+i for i in range(N)])\n",
    "    convergence = False\n",
    "    for m in range(500): #iterate until convergence\n",
    "        for n in range(N):\n",
    "            U_ = U[:]\n",
    "            U_.pop(n)\n",
    "            mode_n_sum = 0\n",
    "            U_kron = kron(U_,reverse=True)\n",
    "            for t in range(T):\n",
    "                unfold_along_n = unfold(Yn[t],mode=n)\n",
    "                mode_n_sum += unfold_along_n@U_kron@U_kron.T@unfold_along_n.T\n",
    "            U[n] = eigsh(mode_n_sum,k=J[n])[1]\n",
    "        \n",
    "        X = multi_mode_dot(Yn,U,modes=[1+i for i in range(N)], transpose=True) # Current cores\n",
    "        \n",
    "        # Check convergence\n",
    "        Yn_apprx = multi_mode_dot(X,U,modes=[1+i for i in range(N)])#Curent approximation\n",
    "        if np.linalg.norm(Yn_apprx-Yn_apprx0) < tol:\n",
    "            print(\"mpca converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            Yn_apprx0 = 1*Yn_apprx\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"mpca has not yet converged\")\n",
    "        \n",
    "    X = multi_mode_dot(Y,U,modes=[1+i for i in range(N)], transpose=True)\n",
    "    Y_apprx = multi_mode_dot(X,U,modes=[1+i for i in range(N)])\n",
    "    print(\"Error in approximation: \", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "\n",
    "    return X,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpca converged at iteration:  0\n",
      "Error in approximation:  1.438973134811144e-15\n"
     ]
    }
   ],
   "source": [
    "X,U = mpca(Y, J=J0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilinear Regression\n",
    "# Ref:MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    "# https://www.jstor.org/stable/43826417?seq=1#metadata_info_tab_contents\n",
    "def multilinear_regression(X,Y,tol=0.0001):\n",
    "    '''\n",
    "    X: Tx?x?x..x? : {X_i}, i=1,..,T\n",
    "    Y: Tx?x?x..x?: {Y_i}, i=1,...,T \n",
    "    N: dimension of the tensor X_i (or Y_i)\n",
    "    J: ranks of the factor matrices\n",
    "    return the model: Y_i = X_ix{U_1,..,U_N}\n",
    "    '''\n",
    "    I = Y.shape\n",
    "    J = X.shape\n",
    "    U = [100*np.random.rand(I[n+1],J[n+1]) for n in range(N)] \n",
    "    #Note: Fix the initialization. Somehow, smaller values of initialization, results in slower convergence.\n",
    "    # Understand this problem\n",
    "    U.insert(0,np.eye(I[0])) \n",
    "    Y_apprx0 = multi_mode_dot(X,U,modes=[i for i in range(N+1)])\n",
    "    convergence = False\n",
    "    for m in range(1000):\n",
    "        for n in range(N):\n",
    "            U_ = U[:]\n",
    "            U_[n+1] = np.eye(J[n+1])\n",
    "            X_tmp = multi_mode_dot(X,U_,modes=[i for i in range(N+1)]) \n",
    "            X_tmp_n = unfold(X_tmp,mode=n+1)\n",
    "            Y_n = unfold(Y,mode=n+1)\n",
    "            U[n+1] = Y_n@pinv(X_tmp_n)\n",
    "            if n<(N-1):#to make sure the values dont blow too much\n",
    "                U[n+1] = U[n+1]/(np.linalg.norm(U[n+1])+1.)\n",
    "       \n",
    "        # Check convergence\n",
    "        Y_apprx = multi_mode_dot(X,U,modes=[i for i in range(N+1)])#Curent approximation\n",
    "        \n",
    "        if np.linalg.norm(Y_apprx-Y_apprx0) < tol:\n",
    "            print(\"Regression converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            if (m+1)%1==0:\n",
    "                print(\"Current error in approximation:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "            Y_apprx0 = 1*Y_apprx\n",
    "\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"Multilinear regression has not yet converged\")\n",
    "    \n",
    "    print(\"Final error in approximation:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "    \n",
    "    return U[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current error in approximation: 0.1367863886640734\n",
      "Current error in approximation: 0.024987484868497986\n",
      "Current error in approximation: 0.015334285393912123\n",
      "Current error in approximation: 0.010797804111172968\n",
      "Current error in approximation: 0.007341408654775449\n",
      "Current error in approximation: 0.004857584495732753\n",
      "Current error in approximation: 0.0033209035030922255\n",
      "Current error in approximation: 0.0023880456770454376\n",
      "Current error in approximation: 0.0017656873380975443\n",
      "Current error in approximation: 0.0013166379877576676\n",
      "Current error in approximation: 0.0009822247379701636\n",
      "Current error in approximation: 0.0007313999667448304\n",
      "Current error in approximation: 0.000543485691624955\n",
      "Current error in approximation: 0.0004031320033105126\n",
      "Current error in approximation: 0.00029861093414901036\n",
      "Current error in approximation: 0.00022095949755927732\n",
      "Current error in approximation: 0.0001633739129786159\n",
      "Current error in approximation: 0.00012072566782060931\n",
      "Current error in approximation: 8.917096275560052e-05\n",
      "Current error in approximation: 6.584108101337234e-05\n",
      "Current error in approximation: 4.860158881070842e-05\n",
      "Current error in approximation: 3.586787333484188e-05\n",
      "Current error in approximation: 2.6465366870543258e-05\n",
      "Regression converged at iteration:  23\n",
      "Final error in approximation: 1.952443590112485e-05\n"
     ]
    }
   ],
   "source": [
    "U = multilinear_regression(X,Y,tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 25, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Array-normal distribution \n",
    "\n",
    "# Compute Matrix root--------------------------------------------------------------------------------------\n",
    "# Compute A's from Cov: Cov = U*S*Vh, A = U*Sqrt(S)\n",
    "def mat_root(Cov,tol=1e-9):\n",
    "    U,s,Vh = np.linalg.svd(Cov)\n",
    "    idx = s>tol\n",
    "    s = s[idx]\n",
    "    U = U[:,idx]   \n",
    "    s_r = np.sqrt(s)\n",
    "    S_r = np.diag(s_r)\n",
    "    S_inv_r = np.diag(1/s_r)\n",
    "    A = U@S_r\n",
    "    A_inv = S_inv_r@U.T\n",
    "    return (A, A_inv) # retun both the sqrt and its inverse\n",
    "\n",
    "# Separable Covariance estimation for N-way array data using MLE\n",
    "def array_normal(X, tol=1e-2): \n",
    "    '''\n",
    "    Data points {Xi}, i=1,..,T are arranged into one array X\n",
    "    Input tensor X. Xi = X[i], i =1,..,T are the data points\n",
    "    '''    \n",
    "    I = X.shape \n",
    "    T = X.shape[0]\n",
    "    N  = len(I)-1 # dimension of the data points X_i\n",
    "    \n",
    "    # Compute the mean:\n",
    "    Xavg = np.average(X,axis=0)\n",
    "    \n",
    "    Xe = X - Xavg\n",
    "\n",
    "    A = [100*np.random.rand(I[i+1],I[i+1]) for i in range(N)]\n",
    "    Cov = [A_@A_.T for A_ in A]   \n",
    "    \n",
    "    # X[i] ~ Xavg + Z x {Cov1, Cov2,..., CovN}, and CovK = Ak*Ak'\n",
    "    A_inv = [None]*T\n",
    "    for n in range(N):\n",
    "        (A[n],A_inv[n]) = mat_root(Cov[n])\n",
    "    A_inv.insert(0,np.identity(T))\n",
    "    A.insert(0,np.identity(T))\n",
    "    Cov.insert(0,np.identity(T))\n",
    "    \n",
    "    for reps in range(100):\n",
    "        for n in range(N): #iterate over each mode\n",
    "            A_inv_ = A_inv[:]\n",
    "            A_ = A[:]\n",
    "            Cov_ = Cov[:]\n",
    "            A_[n+1] = np.eye(I[n+1])\n",
    "            A_inv_[n+1] = np.eye(I[n+1])\n",
    "            Xe_tmp = multi_mode_dot(Xe,A_inv_,modes=[i for i in range(N+1)])\n",
    "            Xe_tmp_n = unfold(Xe_tmp,mode=n+1)\n",
    "            c = T*np.prod(I[1:])/I[n+1]\n",
    "            Cov[n+1] = (Xe_tmp_n@Xe_tmp_n.T)/c\n",
    "            if n<(N-1):#to make sure the values dont blow too much\n",
    "                Cov[n+1] = Cov[n+1]/(np.linalg.norm(Cov[n+1])+1.)\n",
    "                \n",
    "            (A[n+1],A_inv[n+1]) = mat_root(Cov[n+1])\n",
    "         \n",
    "        err = np.linalg.norm(kron(Cov[1:])-kron(Cov_[1:]))\n",
    "        if err<tol:\n",
    "            print(\"MLE for array normal converged in \", reps, \" steps\")\n",
    "            break\n",
    "            \n",
    "    return (Xavg,Cov[1:],A[1:], A_inv[1:])\n",
    "\n",
    "# Sampling from array-normal distribution---------------------------------------------------------------------------\n",
    "def anormal_sampling(Xavg,Cov):\n",
    "    N = len(Xavg.shape)\n",
    "    # Compute the matrix-square-root (Cov = A*A') of covariance matrices\n",
    "    A = [mat_root(Cov[n])[0] for n in range(N)]\n",
    "    Z = np.random.randn(*Xavg.shape)\n",
    "    X = Xavg + multi_mode_dot(Z,A,modes=[n for n in range(N)])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.random.randn(5,6,7,8) # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xavg, Cov, _, _= array_normal(X0) # Fit an array-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsample = anormal_sampling(Xavg,Cov) # sample from the modeled array-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilinear Regression with Array-normal distribution\n",
    "# Ref:MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    "# https://www.jstor.org/stable/43826417?seq=1#metadata_info_tab_contents\n",
    "def anormal_regression(X,Y,tol=0.001):\n",
    "    '''\n",
    "    X: Tx?x?x..x? : {X_i}, i=1,..,T\n",
    "    Y: Tx?x?x..x?: {Y_i}, i=1,...,T \n",
    "    N: dimension of the tensor X_i (or Y_i)\n",
    "    J: ranks of the factor matrices\n",
    "    return the model: Y_i = X_ix{U_1,..,U_N} + N(0,Cov)\n",
    "    '''\n",
    "    I = Y.shape\n",
    "    J = X.shape\n",
    "    T = X.shape[0]\n",
    "    # Initialization of factor matrices\n",
    "    U = [100*np.random.rand(I[n+1],J[n+1]) for n in range(N)] \n",
    "    #Note: Fix the initialization. Somehow, smaller values of initialization, results in slower convergence.\n",
    "    # Understand this problem\n",
    "    U.insert(0,np.eye(I[0])) \n",
    "    Y_apprx0 = multi_mode_dot(X,U,modes=[i for i in range(N+1)]) # current output approximation\n",
    "    print(\"Shape of Y_apprx0: \",Y_apprx0.shape)\n",
    "    # Initialize covariance matrices\n",
    "    A = [100*np.random.rand(I[i+1],I[i+1]) for i in range(N)]\n",
    "    Cov = [A_@A_.T for A_ in A]   \n",
    "    A_inv = [None]*N\n",
    "    for n in range(N):\n",
    "        (A[n],A_inv[n]) = mat_root(Cov[n])\n",
    "    A_inv.insert(0,np.identity(T))\n",
    "    A.insert(0,np.identity(T))\n",
    "    Cov.insert(0,np.identity(T))\n",
    "    convergence = False\n",
    "    for m in range(1000):\n",
    "        # With the current estimation of Covariance (i.e A and A_inv) find the factor matrices U\n",
    "        for reps in range(1):\n",
    "            for n in range(N):\n",
    "                U_ = U[:]\n",
    "                U_[n+1] = np.eye(J[n+1])\n",
    "                A_inv_ = A_inv[:]\n",
    "                A_inv_.pop(n+1)\n",
    "                X_tmp = multi_mode_dot(X,U_,modes=[i for i in range(N+1)]) \n",
    "                modes=[i+1 for i in range(N)]\n",
    "                modes.pop(n)\n",
    "                X_tmp_rescaled = multi_mode_dot(X_tmp, A_inv_[1:],modes=modes)\n",
    "                X_tmp_rescaled_n = unfold(X_tmp_rescaled,mode=n+1)\n",
    "                Y_rescaled = multi_mode_dot(Y, A_inv_[1:],modes=modes)\n",
    "                Y_rescaled_n = unfold(Y_rescaled,mode=n+1)\n",
    "                U[n+1] = Y_rescaled_n@pinv(X_tmp_rescaled_n)\n",
    "                if n<(N-1): # to make sure the values dont blow too much\n",
    "                    U[n+1] = U[n+1]/(np.linalg.norm(U[n+1])+1e-2)\n",
    "\n",
    "        # With the current estimation of factor matrices find the Covariances\n",
    "        Xe = Y-multi_mode_dot(X,U,modes=[i for i in range(N+1)]) # Error in approximation\n",
    "        Xe = Xe-np.average(Xe,axis=0) # subtract the mean\n",
    "        for reps in range(1):\n",
    "            for n in range(N):\n",
    "                A_inv_ = A_inv[:]\n",
    "                A_ = A[:]\n",
    "                Cov_ = Cov[:]\n",
    "                A_[n+1] = np.eye(I[n+1])\n",
    "                A_inv_[n+1] = np.eye(I[n+1])\n",
    "                Xe_tmp = multi_mode_dot(Xe,A_inv_[1:],modes=[i+1 for i in range(N)])\n",
    "                Xe_tmp_n = unfold(Xe_tmp,mode=n+1)\n",
    "                c = T*np.prod(I[1:])/I[n+1]\n",
    "                Cov[n+1] = (Xe_tmp_n@Xe_tmp_n.T)/c\n",
    "                if n<(N-1):#to make sure the values dont blow too much\n",
    "                    Cov[n+1] = Cov[n+1]/(np.linalg.norm(Cov[n+1])+1e-2)\n",
    "                (A[n+1],A_inv[n+1]) = mat_root(Cov[n+1])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Check convergence\n",
    "        Y_apprx = multi_mode_dot(X,U,modes=[i for i in range(N+1)])#Curent approximation\n",
    "        err_cov = np.linalg.norm(kron(Cov[1:])-kron(Cov_[1:]))\n",
    "        err_reg = np.linalg.norm(Y_apprx-Y_apprx0)/np.linalg.norm(Y_apprx)\n",
    "        print(\"Current error in approximation | U:\", err_reg, \" | Cov: \", err_cov)\n",
    "\n",
    "        if  err_cov < tol and err_reg < tol:\n",
    "            print(\"Regression converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            Y_apprx0 = 1*Y_apprx\n",
    "\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"Multilinear regression has not yet converged\")\n",
    "    print(\"Final error in approximation of Y = X x {U_1,..,U_N}:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "    return (U[1:],Cov[1:],A[1:], A_inv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_apprx0:  (10, 20, 25, 4)\n",
      "Current error in approximation | U: 3160301.1363525987  | Cov:  439.0838619156021\n",
      "Current error in approximation | U: 0.2316112560076902  | Cov:  12506.31252469037\n",
      "Current error in approximation | U: 0.0583344322875933  | Cov:  3994.6459315597713\n",
      "Current error in approximation | U: 0.02968872553623238  | Cov:  42.604162907569524\n",
      "Current error in approximation | U: 0.010467188987201413  | Cov:  1.8678463650918116\n",
      "Current error in approximation | U: 0.005838763692480185  | Cov:  0.2062710833494576\n",
      "Current error in approximation | U: 0.00507257236640154  | Cov:  0.05679623120007263\n",
      "Current error in approximation | U: 0.004614715128676233  | Cov:  0.05056364118574026\n",
      "Current error in approximation | U: 0.0042954099538934625  | Cov:  0.026379808619163118\n",
      "Current error in approximation | U: 0.003978661738891003  | Cov:  0.06471808480357528\n",
      "Current error in approximation | U: 0.003697288613954303  | Cov:  0.1377373214615133\n",
      "Current error in approximation | U: 0.0034799349723481014  | Cov:  0.21004560760915256\n",
      "Current error in approximation | U: 0.0032735528180711597  | Cov:  0.26251908377647853\n",
      "Current error in approximation | U: 0.002997434634001758  | Cov:  0.286668632958161\n",
      "Current error in approximation | U: 0.0026271949933376272  | Cov:  0.28585527814297096\n",
      "Current error in approximation | U: 0.0022072327890439647  | Cov:  0.269611989234366\n",
      "Current error in approximation | U: 0.0018028719061203872  | Cov:  0.24661865983903908\n",
      "Current error in approximation | U: 0.0014576483984298407  | Cov:  0.22187841049211804\n",
      "Current error in approximation | U: 0.0011845491713217261  | Cov:  0.19753784019309167\n",
      "Current error in approximation | U: 0.0009770859023645279  | Cov:  0.1744302402721767\n",
      "Current error in approximation | U: 0.0008216820739810461  | Cov:  0.1529579847033573\n",
      "Current error in approximation | U: 0.000704827186642876  | Cov:  0.13337046142874176\n",
      "Current error in approximation | U: 0.0006157251924521667  | Cov:  0.11580018586268101\n",
      "Current error in approximation | U: 0.0005465697965238032  | Cov:  0.10026262104949515\n",
      "Current error in approximation | U: 0.0004919537119816424  | Cov:  0.08667466283133961\n",
      "Current error in approximation | U: 0.00044815603049309997  | Cov:  0.07488686882634335\n",
      "Current error in approximation | U: 0.000412572075603568  | Cov:  0.06471578125497522\n",
      "Current error in approximation | U: 0.0003833244942126255  | Cov:  0.055968817432954496\n",
      "Current error in approximation | U: 0.0003590177215221003  | Cov:  0.04846026517543726\n",
      "Current error in approximation | U: 0.00033858756766728097  | Cov:  0.04201992072855373\n",
      "Current error in approximation | U: 0.0003212083998859787  | Cov:  0.03649665703261349\n",
      "Current error in approximation | U: 0.0003062335612421717  | Cov:  0.031758921052184405\n",
      "Current error in approximation | U: 0.00029315473120257533  | Cov:  0.027693587061511146\n",
      "Current error in approximation | U: 0.00028157237700406366  | Cov:  0.024204069521211253\n",
      "Current error in approximation | U: 0.00027117315372309007  | Cov:  0.02120821754147069\n",
      "Current error in approximation | U: 0.000261712077988065  | Cov:  0.01863626597759549\n",
      "Current error in approximation | U: 0.00025299827356254257  | Cov:  0.016428970856643254\n",
      "Current error in approximation | U: 0.000244883544252905  | Cov:  0.014535974615808177\n",
      "Current error in approximation | U: 0.00023725324294819153  | Cov:  0.012914403907855511\n",
      "Current error in approximation | U: 0.00023001901484725142  | Cov:  0.011527682619096173\n",
      "Current error in approximation | U: 0.0002231130622126765  | Cov:  0.010344534959608676\n",
      "Current error in approximation | U: 0.00021648363304526178  | Cov:  0.009338152036539163\n",
      "Current error in approximation | U: 0.00021009148489118434  | Cov:  0.008485496875716186\n",
      "Current error in approximation | U: 0.0002039071192004053  | Cov:  0.007766725596246547\n",
      "Current error in approximation | U: 0.00019790862063352033  | Cov:  0.007164705454289568\n",
      "Current error in approximation | U: 0.00019207996926326804  | Cov:  0.006664613301482879\n",
      "Current error in approximation | U: 0.00018640972143006227  | Cov:  0.006253600500420824\n",
      "Current error in approximation | U: 0.00018088997777255451  | Cov:  0.005920512503279742\n",
      "Current error in approximation | U: 0.00017551557505636117  | Cov:  0.005655653191692917\n",
      "Current error in approximation | U: 0.0001702834527190851  | Cov:  0.005450585787473447\n",
      "Current error in approximation | U: 0.00016519215617652008  | Cov:  0.005297963704217048\n",
      "Current error in approximation | U: 0.00016024144756125432  | Cov:  0.005191386112513118\n",
      "Current error in approximation | U: 0.00015543200118903146  | Cov:  0.00512527417968187\n",
      "Current error in approximation | U: 0.00015076516613796832  | Cov:  0.005094764879042545\n",
      "Current error in approximation | U: 0.0001462427822430068  | Cov:  0.005095619925171666\n",
      "Current error in approximation | U: 0.00014186703876480276  | Cov:  0.0051241478245862985\n",
      "Current error in approximation | U: 0.00013764036734000972  | Cov:  0.005177137307584324\n",
      "Current error in approximation | U: 0.0001335653625192927  | Cov:  0.005251800589867354\n",
      "Current error in approximation | U: 0.00012964472462335033  | Cov:  0.00534572506843292\n",
      "Current error in approximation | U: 0.0001258812206661076  | Cov:  0.005456832210717755\n",
      "Current error in approximation | U: 0.00012227765993884146  | Cov:  0.005583342555917324\n",
      "Current error in approximation | U: 0.00011883688149637676  | Cov:  0.0057237459102028685\n",
      "Current error in approximation | U: 0.00011556175132999612  | Cov:  0.0058767759746369596\n",
      "Current error in approximation | U: 0.00011245516742833773  | Cov:  0.006041388787879318\n",
      "Current error in approximation | U: 0.00010952007131619189  | Cov:  0.006216744491689742\n",
      "Current error in approximation | U: 0.000106759464996801  | Cov:  0.0064021920299917\n",
      "Current error in approximation | U: 0.00010417643252219612  | Cov:  0.006597256487852702\n",
      "Current error in approximation | U: 0.00010177416575748507  | Cov:  0.006801628844278276\n",
      "Current error in approximation | U: 9.955599420912805e-05  | Cov:  0.007015157983588213\n",
      "Current error in approximation | U: 9.75254191454434e-05  | Cov:  0.007237844859729319\n",
      "Current error in approximation | U: 9.568615264567708e-05  | Cov:  0.0074698387644954005\n",
      "Current error in approximation | U: 9.404216259919162e-05  | Cov:  0.007711435695999662\n",
      "Current error in approximation | U: 9.259772520534724e-05  | Cov:  0.007963078872480744\n",
      "Current error in approximation | U: 9.135748698336581e-05  | Cov:  0.008225361492132686\n",
      "Current error in approximation | U: 9.032653890872414e-05  | Cov:  0.008499031889745214\n",
      "Current error in approximation | U: 8.951050586652211e-05  | Cov:  0.008785001311835858\n",
      "Current error in approximation | U: 8.891565525130937e-05  | Cov:  0.009084354600245552\n",
      "Current error in approximation | U: 8.854902924674009e-05  | Cov:  0.009398364168724771\n",
      "Current error in approximation | U: 8.841860606993089e-05  | Cov:  0.00972850776206757\n",
      "Current error in approximation | U: 8.853349634171143e-05  | Cov:  0.010076490621329018\n",
      "Current error in approximation | U: 8.890418180051293e-05  | Cov:  0.010444272847734935\n",
      "Current error in approximation | U: 8.954280493462358e-05  | Cov:  0.010834102963597865\n",
      "Current error in approximation | U: 9.046351986066441e-05  | Cov:  0.011248558942441957\n",
      "Current error in approximation | U: 9.168291721425188e-05  | Cov:  0.011690598317909856\n",
      "Current error in approximation | U: 9.32205390774444e-05  | Cov:  0.012163619433937652\n",
      "Current error in approximation | U: 9.509950452421668e-05  | Cov:  0.012671536475194416\n",
      "Current error in approximation | U: 9.734727257879836e-05  | Cov:  0.01321887169399788\n",
      "Current error in approximation | U: 9.999657791865717e-05  | Cov:  0.013810869266736676\n",
      "Current error in approximation | U: 0.0001030865864174212  | Cov:  0.014453636594483125\n",
      "Current error in approximation | U: 0.00010666433383892374  | Cov:  0.015154320730416209\n",
      "Current error in approximation | U: 0.00011078653349980342  | Cov:  0.015921330174890492\n",
      "Current error in approximation | U: 0.00011552187030538572  | Cov:  0.016764615839409348\n",
      "Current error in approximation | U: 0.00012095394331169412  | Cov:  0.017696029965841728\n",
      "Current error in approximation | U: 0.0001271850832619637  | Cov:  0.01872978888721219\n",
      "Current error in approximation | U: 0.00013434136530552162  | Cov:  0.019883075751320912\n",
      "Current error in approximation | U: 0.00014257927602985313  | Cov:  0.02117683432399545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current error in approximation | U: 0.0001520947034722208  | Cov:  0.022636827312250068\n",
      "Current error in approximation | U: 0.0001631352408829197  | Cov:  0.02429506650707605\n",
      "Current error in approximation | U: 0.00017601730072782566  | Cov:  0.02619177443460348\n",
      "Current error in approximation | U: 0.00019115034774340746  | Cov:  0.028378120084791663\n",
      "Current error in approximation | U: 0.00020907189857585312  | Cov:  0.030920105698993457\n",
      "Current error in approximation | U: 0.00023049920523695756  | Cov:  0.03390420572150329\n",
      "Current error in approximation | U: 0.000256407513023838  | Cov:  0.037445744655047755\n",
      "Current error in approximation | U: 0.0002881519964163668  | Cov:  0.041701688298817714\n",
      "Current error in approximation | U: 0.00032766412525967945  | Cov:  0.0468908009861935\n",
      "Current error in approximation | U: 0.0003777803120772003  | Cov:  0.05332661358995591\n",
      "Current error in approximation | U: 0.0004428176080124104  | Cov:  0.061473788869203794\n",
      "Current error in approximation | U: 0.0005296390294810125  | Cov:  0.07204981955286034\n",
      "Current error in approximation | U: 0.0006497623096265476  | Cov:  0.08622117287633438\n",
      "Current error in approximation | U: 0.0008239033006868926  | Cov:  0.106014930254294\n",
      "Current error in approximation | U: 0.0010929035688941884  | Cov:  0.13528244965383604\n",
      "Current error in approximation | U: 0.0015482252346826224  | Cov:  0.1823029649183557\n",
      "Current error in approximation | U: 0.0024371065790564305  | Cov:  0.2682230360030488\n",
      "Current error in approximation | U: 0.004662567474743392  | Cov:  0.4589015916856434\n",
      "Current error in approximation | U: 0.013475577839495635  | Cov:  0.8079446133386944\n",
      "Current error in approximation | U: 0.030150579446203963  | Cov:  5.256405701343003\n",
      "Current error in approximation | U: 0.023377130456359915  | Cov:  5.185083564591113\n",
      "Current error in approximation | U: 0.004245602931513372  | Cov:  0.8034662448574931\n",
      "Current error in approximation | U: 0.002336626931385995  | Cov:  0.39240314035852786\n",
      "Current error in approximation | U: 0.01335181260904641  | Cov:  0.9663024941517072\n",
      "Current error in approximation | U: 0.0011375509583451335  | Cov:  0.07970893861734438\n",
      "Current error in approximation | U: 0.0011483530077058116  | Cov:  0.0004953520777596449\n",
      "Current error in approximation | U: 0.00016430727091575374  | Cov:  2.6736895952558213e-06\n",
      "Regression converged at iteration:  122\n",
      "Final error in approximation of Y = X x {U_1,..,U_N}: 1.5849341195588083e-05\n"
     ]
    }
   ],
   "source": [
    "U, Cov, A, A_inv = anormal_regression(X,Y,tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
