{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Suhan Shetty (suhan.n.shetty@gmail.com | suhan.shetty@idiap.ch)\n",
    "\n",
    "This notebook implements multilinear PCA based regression for tensor time series modeling\n",
    "\n",
    "References:\n",
    "\n",
    " - Dynamic tensor time series modeling and analysis, https://ieeexplore.ieee.org/abstract/document/7798500\n",
    "\n",
    " - MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    " https://www.jstor.org/stable/43826417\n",
    " \n",
    " - Multilinear Dynamical Systems for Tensor Time Series: https://people.eecs.berkeley.edu/~russell/papers/nips13-tensor.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.tenalg import multi_mode_dot\n",
    "from tensorly.base import unfold\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.linalg import pinv\n",
    "from tensorly.tenalg import kronecker as kron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3 # dimension of each output tensor Yi's\n",
    "T = 100 # length of time series\n",
    "shape_Yi = [32,32,5]\n",
    "I = [T,*shape_Yi]\n",
    "\n",
    "# Generate data Y from some low-rank structure \n",
    "J0 = [15,20,3] # ranks of the factor matrices\n",
    "U0 = [np.random.rand(I[n+1],J0[n]) for n in range(N)] #Factors\n",
    "X0 = np.random.rand(T,*J0) # Core array\n",
    "\n",
    "Y = multi_mode_dot(X0,U0, modes=[n+1 for n in range(N)]) #Output tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mean = np.average(Y,axis=0)\n",
    "Yn = Y - Y_mean # mean zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpca(Y,J,tol=1e-2):\n",
    "    '''\n",
    "    Y: an N-dimensional Tensor\n",
    "    J: Desired ranks of the tucker factors (increase J for better approximation)\n",
    "    tol: tolerance for convergence of mpca iterations\n",
    "    '''\n",
    "    Yn = Y-np.average(Y,axis=0)\n",
    "    # Initialization\n",
    "    U = [None]*(len(Yn.shape)-1)\n",
    "    for n in range(N): # across all modes\n",
    "        mode_n_sum = 0\n",
    "        for t in range(T):\n",
    "            unfold_along_n = unfold(Yn[t],mode=n)\n",
    "            mode_n_sum += unfold_along_n@unfold_along_n.T\n",
    "        U[n] = eigsh(mode_n_sum,k=J[n])[1] # faster way to compute eigen vectors (for symmetric matrices)\n",
    "        # Note: The most significant eigen vectors are arranged in the last columns of U\n",
    "    \n",
    "    # Local optimization\n",
    "    X = multi_mode_dot(Yn,U,modes=[1+i for i in range(N)], transpose=True)\n",
    "    Yn_apprx0 = multi_mode_dot(X,U,modes=[1+i for i in range(N)])\n",
    "    convergence = False\n",
    "    for m in range(500): #iterate until convergence\n",
    "        for n in range(N):\n",
    "            U_ = U[:]\n",
    "            U_.pop(n)\n",
    "            mode_n_sum = 0\n",
    "            U_kron = kron(U_,reverse=True)\n",
    "            for t in range(T):\n",
    "                unfold_along_n = unfold(Yn[t],mode=n)\n",
    "                mode_n_sum += unfold_along_n@U_kron@U_kron.T@unfold_along_n.T\n",
    "            U[n] = eigsh(mode_n_sum,k=J[n])[1]\n",
    "        \n",
    "        X = multi_mode_dot(Yn,U,modes=[1+i for i in range(N)], transpose=True) # Current cores\n",
    "        \n",
    "        # Check convergence\n",
    "        Yn_apprx = multi_mode_dot(X,U,modes=[1+i for i in range(N)])#Curent approximation\n",
    "        if np.linalg.norm(Yn_apprx-Yn_apprx0) < tol:\n",
    "            print(\"mpca converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            Yn_apprx0 = 1*Yn_apprx\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"mpca has not yet converged\")\n",
    "        \n",
    "    X = multi_mode_dot(Y,U,modes=[1+i for i in range(N)], transpose=True)\n",
    "    Y_apprx = multi_mode_dot(X,U,modes=[1+i for i in range(N)])\n",
    "    print(\"Error in approximation: \", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "\n",
    "    return X,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mpca converged at iteration:  0\n",
      "Error in approximation:  8.983225110648771e-16\n"
     ]
    }
   ],
   "source": [
    "X,U = mpca(Y, J=J0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilinear Regression\n",
    "# Ref:MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    "# https://www.jstor.org/stable/43826417?seq=1#metadata_info_tab_contents\n",
    "def multilinear_regression(X,Y,tol=0.0001):\n",
    "    '''\n",
    "    X: Tx?x?x..x? : {X_i}, i=1,..,T\n",
    "    Y: Tx?x?x..x?: {Y_i}, i=1,...,T \n",
    "    N: dimension of the tensor X_i (or Y_i)\n",
    "    J: ranks of the factor matrices\n",
    "    return the model: Y_i = X_ix{U_1,..,U_N}\n",
    "    '''\n",
    "    I = Y.shape\n",
    "    J = X.shape\n",
    "    U = [100*np.random.rand(I[n+1],J[n+1]) for n in range(N)] \n",
    "    #Note: Fix the initialization. Somehow, smaller values of initialization, results in slower convergence.\n",
    "    # Understand this problem\n",
    "    U.insert(0,np.eye(I[0])) \n",
    "    Y_apprx0 = multi_mode_dot(X,U,modes=[i for i in range(N+1)])\n",
    "    convergence = False\n",
    "    for m in range(1000):\n",
    "        for n in range(N):\n",
    "            U_ = U[:]\n",
    "            U_[n+1] = np.eye(J[n+1])\n",
    "            X_tmp = multi_mode_dot(X,U_,modes=[i for i in range(N+1)]) \n",
    "            X_tmp_n = unfold(X_tmp,mode=n+1)\n",
    "            Y_n = unfold(Y,mode=n+1)\n",
    "            U[n+1] = Y_n@pinv(X_tmp_n)\n",
    "            if n<(N-1):#to make sure the values dont blow too much\n",
    "                U[n+1] = U[n+1]/(np.linalg.norm(U[n+1])+1.)\n",
    "       \n",
    "        # Check convergence\n",
    "        Y_apprx = multi_mode_dot(X,U,modes=[i for i in range(N+1)])#Curent approximation\n",
    "        \n",
    "        if np.linalg.norm(Y_apprx-Y_apprx0) < tol:\n",
    "            print(\"Regression converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            if (m+1)%1==0:\n",
    "                print(\"Current error in approximation:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "            Y_apprx0 = 1*Y_apprx\n",
    "\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"Multilinear regression has not yet converged\")\n",
    "    \n",
    "    print(\"Final error in approximation:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "    \n",
    "    return U[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current error in approximation: 0.07689088135692322\n",
      "Current error in approximation: 0.004375508413595701\n",
      "Current error in approximation: 0.0006952831545306575\n",
      "Current error in approximation: 0.0001388050684602708\n",
      "Current error in approximation: 3.266251127994519e-05\n",
      "Current error in approximation: 8.12908517718187e-06\n",
      "Current error in approximation: 2.06988042732246e-06\n",
      "Current error in approximation: 5.343555608891442e-07\n",
      "Current error in approximation: 1.3942544256873205e-07\n",
      "Regression converged at iteration:  9\n",
      "Final error in approximation: 3.6715126122381255e-08\n"
     ]
    }
   ],
   "source": [
    "U = multilinear_regression(X,Y,tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 32, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Array-normal distribution \n",
    "\n",
    "# Compute Matrix root--------------------------------------------------------------------------------------\n",
    "# Compute A's from Cov: Cov = U*S*Vh, A = U*Sqrt(S)\n",
    "def mat_root(Cov,tol=1e-9):\n",
    "    U,s,Vh = np.linalg.svd(Cov)\n",
    "    idx = s>tol\n",
    "    s = s[idx]\n",
    "    U = U[:,idx]   \n",
    "    s_r = np.sqrt(s)\n",
    "    S_r = np.diag(s_r)\n",
    "    S_inv_r = np.diag(1/s_r)\n",
    "    A = U@S_r\n",
    "    A_inv = S_inv_r@U.T\n",
    "    return (A, A_inv) # retun both the sqrt and its inverse\n",
    "\n",
    "# Separable Covariance estimation for N-way array data using MLE\n",
    "def array_normal(X, tol=1e-2): \n",
    "    '''\n",
    "    Data points {Xi}, i=1,..,T are arranged into one array X\n",
    "    Input tensor X. Xi = X[i], i =1,..,T are the data points\n",
    "    '''    \n",
    "    I = X.shape \n",
    "    T = X.shape[0]\n",
    "    N  = len(I)-1 # dimension of the data points X_i\n",
    "    \n",
    "    # Compute the mean:\n",
    "    Xavg = np.average(X,axis=0)\n",
    "    \n",
    "    Xe = X - Xavg\n",
    "\n",
    "    A = [100*np.random.rand(I[i+1],I[i+1]) for i in range(N)]\n",
    "    Cov = [A_@A_.T for A_ in A]   \n",
    "    \n",
    "    # X[i] ~ Xavg + Z x {Cov1, Cov2,..., CovN}, and CovK = Ak*Ak'\n",
    "    A_inv = [None]*T\n",
    "    for n in range(N):\n",
    "        (A[n],A_inv[n]) = mat_root(Cov[n])\n",
    "    A_inv.insert(0,np.identity(T))\n",
    "    A.insert(0,np.identity(T))\n",
    "    Cov.insert(0,np.identity(T))\n",
    "    \n",
    "    for reps in range(100):\n",
    "        for n in range(N): #iterate over each mode\n",
    "            A_inv_ = A_inv[:]\n",
    "            A_ = A[:]\n",
    "            Cov_ = Cov[:]\n",
    "            A_[n+1] = np.eye(I[n+1])\n",
    "            A_inv_[n+1] = np.eye(I[n+1])\n",
    "            Xe_tmp = multi_mode_dot(Xe,A_inv_,modes=[i for i in range(N+1)])\n",
    "            Xe_tmp_n = unfold(Xe_tmp,mode=n+1)\n",
    "            c = T*np.prod(I[1:])/I[n+1]\n",
    "            Cov[n+1] = (Xe_tmp_n@Xe_tmp_n.T)/c\n",
    "            if n<(N-1):#to make sure the values dont blow too much\n",
    "                Cov[n+1] = Cov[n+1]/(np.linalg.norm(Cov[n+1])+1.)\n",
    "                \n",
    "            (A[n+1],A_inv[n+1]) = mat_root(Cov[n+1])\n",
    "         \n",
    "        err = np.linalg.norm(kron(Cov[1:])-kron(Cov_[1:]))\n",
    "        if err<tol:\n",
    "            print(\"MLE for array normal converged in \", reps, \" steps\")\n",
    "            break\n",
    "            \n",
    "    return (Xavg,Cov[1:],A[1:], A_inv[1:])\n",
    "\n",
    "# Sampling from array-normal distribution---------------------------------------------------------------------------\n",
    "def anormal_sampling(Xavg,Cov):\n",
    "    N = len(Xavg.shape)\n",
    "    # Compute the matrix-square-root (Cov = A*A') of covariance matrices\n",
    "    A = [mat_root(Cov[n])[0] for n in range(N)]\n",
    "    Z = np.random.randn(*Xavg.shape)\n",
    "    X = Xavg + multi_mode_dot(Z,A,modes=[n for n in range(N)])\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = np.random.randn(5,6,7,8) # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xavg, Cov, _, _= array_normal(X0, tol=0.01) # Fit an array-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsample = anormal_sampling(Xavg,Cov) # sample from the modeled array-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilinear Regression with Array-normal distribution\n",
    "# Ref:MULTILINEAR TENSOR REGRESSION FOR LONGITUDINAL RELATIONAL DATA:\n",
    "# https://www.jstor.org/stable/43826417?seq=1#metadata_info_tab_contents\n",
    "def anormal_regression(X,Y,tol=0.001):\n",
    "    '''\n",
    "    X: Tx?x?x..x? : {X_i}, i=1,..,T\n",
    "    Y: Tx?x?x..x?: {Y_i}, i=1,...,T \n",
    "    N: dimension of the tensor X_i (or Y_i)\n",
    "    J: ranks of the factor matrices\n",
    "    return the model: Y_i = X_ix{U_1,..,U_N} + N(0,Cov)\n",
    "    '''\n",
    "    I = Y.shape\n",
    "    J = X.shape\n",
    "    T = X.shape[0]\n",
    "    # Initialization of factor matrices\n",
    "    U = [100*np.random.rand(I[n+1],J[n+1]) for n in range(N)] \n",
    "    #Note: Fix the initialization. Somehow, smaller values of initialization, results in slower convergence.\n",
    "    # Understand this problem\n",
    "    U.insert(0,np.eye(I[0])) \n",
    "    Y_apprx0 = multi_mode_dot(X,U,modes=[i for i in range(N+1)]) # current output approximation\n",
    "    print(\"Shape of Y_apprx0: \",Y_apprx0.shape)\n",
    "    # Initialize covariance matrices\n",
    "    A = [100*np.random.rand(I[i+1],I[i+1]) for i in range(N)]\n",
    "    Cov = [A_@A_.T for A_ in A]   \n",
    "    A_inv = [None]*N\n",
    "    for n in range(N):\n",
    "        (A[n],A_inv[n]) = mat_root(Cov[n])\n",
    "    A_inv.insert(0,np.identity(T))\n",
    "    A.insert(0,np.identity(T))\n",
    "    Cov.insert(0,np.identity(T))\n",
    "    convergence = False\n",
    "    for m in range(1000):\n",
    "        # With the current estimation of Covariance (i.e A and A_inv) find the factor matrices U\n",
    "        for reps in range(1):\n",
    "            for n in range(N):\n",
    "                U_ = U[:]\n",
    "                U_[n+1] = np.eye(J[n+1])\n",
    "                A_inv_ = A_inv[:]\n",
    "                A_inv_.pop(n+1)\n",
    "                X_tmp = multi_mode_dot(X,U_,modes=[i for i in range(N+1)]) \n",
    "                modes=[i+1 for i in range(N)]\n",
    "                modes.pop(n)\n",
    "                X_tmp_rescaled = multi_mode_dot(X_tmp, A_inv_[1:],modes=modes)\n",
    "                X_tmp_rescaled_n = unfold(X_tmp_rescaled,mode=n+1)\n",
    "                Y_rescaled = multi_mode_dot(Y, A_inv_[1:],modes=modes)\n",
    "                Y_rescaled_n = unfold(Y_rescaled,mode=n+1)\n",
    "                U[n+1] = Y_rescaled_n@pinv(X_tmp_rescaled_n)\n",
    "                if n<(N-1): # to make sure the values dont blow too much\n",
    "                    U[n+1] = U[n+1]/(np.linalg.norm(U[n+1])+1e-2)\n",
    "\n",
    "        # With the current estimation of factor matrices find the Covariances\n",
    "        Xe = Y-multi_mode_dot(X,U,modes=[i for i in range(N+1)]) # Error in approximation\n",
    "        Xe = Xe-np.average(Xe,axis=0) # subtract the mean\n",
    "        for reps in range(5):\n",
    "            for n in range(N):\n",
    "                A_inv_ = A_inv[:]\n",
    "                A_ = A[:]\n",
    "                Cov_ = Cov[:]\n",
    "                A_[n+1] = np.eye(I[n+1])\n",
    "                A_inv_[n+1] = np.eye(I[n+1])\n",
    "                Xe_tmp = multi_mode_dot(Xe,A_inv_[1:],modes=[i+1 for i in range(N)])\n",
    "                Xe_tmp_n = unfold(Xe_tmp,mode=n+1)\n",
    "                c = T*np.prod(I[1:])/I[n+1]\n",
    "                Cov[n+1] = (Xe_tmp_n@Xe_tmp_n.T)/c\n",
    "                if n<(N-1):#to make sure the values dont blow too much\n",
    "                    Cov[n+1] = Cov[n+1]/(np.linalg.norm(Cov[n+1])+1e-2)\n",
    "                (A[n+1],A_inv[n+1]) = mat_root(Cov[n+1])\n",
    "\n",
    "        \n",
    "        \n",
    "        # Check convergence\n",
    "        Y_apprx = multi_mode_dot(X,U,modes=[i for i in range(N+1)])#Curent approximation\n",
    "        err_cov = np.linalg.norm(kron(Cov[1:])-kron(Cov_[1:]))\n",
    "        err_reg = np.linalg.norm(Y_apprx-Y_apprx0)/np.linalg.norm(Y_apprx)\n",
    "        print(\"Current error in approximation | U:\", err_reg, \" | Cov: \", err_cov)\n",
    "\n",
    "        if  err_cov < tol and err_reg < tol:\n",
    "            print(\"Regression converged at iteration: \",m)\n",
    "            convergence = True\n",
    "            break\n",
    "        else:\n",
    "            Y_apprx0 = 1*Y_apprx\n",
    "\n",
    "    \n",
    "    if convergence==False:\n",
    "        print(\"Multilinear regression has not yet converged\")\n",
    "    print(\"Final error in approximation of Y = X x {U_1,..,U_N}:\", np.linalg.norm(Y-Y_apprx)/np.linalg.norm(Y))\n",
    "    return (U[1:],Cov[1:],A[1:], A_inv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_apprx0:  (100, 32, 32, 5)\n",
      "Current error in approximation | U: 63790288.31963627  | Cov:  7.319982924894561\n",
      "Current error in approximation | U: 0.7503340812583458  | Cov:  0.0022880231408216444\n",
      "Current error in approximation | U: 0.033399652181985436  | Cov:  495.5614588313141\n",
      "Current error in approximation | U: 0.08586984422553834  | Cov:  0.413248948672643\n",
      "Current error in approximation | U: 0.09006379907389192  | Cov:  4.752395978021957e-06\n",
      "Current error in approximation | U: 0.00032839369129261984  | Cov:  2.0722034920225093e-08\n",
      "Regression converged at iteration:  5\n",
      "Final error in approximation of Y = X x {U_1,..,U_N}: 5.347387675559351e-07\n"
     ]
    }
   ],
   "source": [
    "U, Cov, A, A_inv = anormal_regression(X,Y,tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
